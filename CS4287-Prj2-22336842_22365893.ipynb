{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b75af1",
   "metadata": {},
   "source": [
    "**Team Members:** Michael Cronin (22336842), Darren Nugent (22365893)  \n",
    "**Code Executes to End:** Yes  \n",
    "**Third-Party Code:** None - implementation follows lectures (but converted to PyTorch) and Mnih et al. (2015) paper specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d57993",
   "metadata": {},
   "source": [
    "# CS4287 Assignment 2 Option 2: Deep Q-Learning for Space Invaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a3bed",
   "metadata": {},
   "source": [
    "## 1. Why RL for Space Invaders?\n",
    "\n",
    "There are multiple reasons why RL is the perfect choice for Space Invaders. The main and obvious one being trial and error learning. Just like a human, a RL agent learns through interaction with the environment. It will discover shooting aliens generates a reward whereas getting hit will produce a negative reward, eventually ending the episode. All this is learned without explicit programming of these rules. There is a delayed reward aspect in the game which makes Rl learning the right choice also. Making decisions such as preserving shileds or targeting mystery ships require understanding that there are delayed rewards involved. There is a dynamic difficulty component to this game also. As aliens are shot, the remining ones speed up. A RL agent will deal with this by continuously updating its policy based on the current state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68727169",
   "metadata": {},
   "source": [
    "## 1. Why RL for Space Invaders?\n",
    "\n",
    "Reinforcement Learning is ideal for Space Invaders because the game naturally fits the Markov Decision Process (MDP) framework: an agent observes a state (game screen), takes an action (move/shoot), receives a reward (points), and transitions to a new state.\n",
    "\n",
    "There are multiple reasons why RL is the perfect choice for Space Invaders. The main and obvious one being trial and error learning. Just like a human, an RL agent learns through interaction with the environment. It will discover shooting aliens generates a reward whereas getting hit will produce a negative reward, eventually ending the episode. All this is learned without explicit programming of these rules. There is a delayed reward aspect in the game which makes RL the right choice also. Making decisions such as preserving shields or targeting mystery ships require understanding that there are delayed rewards involved. There is a dynamic difficulty component to this game also. As aliens are shot, the remaining ones speed up. An RL agent will deal with this by continuously updating its policy based on the current state.\n",
    "\n",
    "Supervised learning would require a dataset of \"correct\" actions for every possible game state, which doesn't exist. Unsupervised learning has no mechanism to optimise for game score. Only RL can learn optimal policies through direct environment interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a209c0",
   "metadata": {},
   "source": [
    "## 2. The Gym Environment\n",
    "\n",
    "The environment is ALE/SpaceInvaders-v5 and has an observation space of shape (210, 160, 3) with an observation high of 255 and a low of 0. \n",
    "There is an action space of Discrete(6) with the player having 3 lives per episode.\n",
    "\n",
    "**Action Space**: Space Invaders provides 6 discrete actions: / **Reward Structure**: Points are awarded for destroying aliens, with higher rows worth more:\n",
    "\n",
    "| Action ID | Action Name | Description        |    | Target        | Points         |\n",
    "|-----------|-------------|--------------------|---------|---------------|----------------|\n",
    "| 0         | NOOP        | No operation       |        | Bottom row    | 10             |\n",
    "| 1         | FIRE        | Shoot while stationary |   | Second row   | 20             |\n",
    "| 2         | RIGHT       | Move right         |   | Third row     | 30             |\n",
    "| 3         | LEFT        | Move left          |   | Top row       | 40             |\n",
    "| 4         | RIGHTFIRE   | Move right and shoot |   | Mystery ship | 50-200 (random)|\n",
    "| 5         | LEFTFIRE    | Move left and shoot |   |               |                |\n",
    "\n",
    "The environment provides 210×160×3 RGB observations at each timestep. These raw frames are preprocessed to 84×84 grayscale images and stacked in groups of 4 to provide temporal information about motion and velocity. The reward signal guides the agent's policy optimisation through the Q-learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18354e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ale_py in ./.venv/lib/python3.10/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>1.20 in ./.venv/lib/python3.10/site-packages (from ale_py) (2.2.6)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from ale_py) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gymnasium[atari] in ./.venv/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./.venv/lib/python3.10/site-packages (from gymnasium[atari]) (2.2.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.10/site-packages (from gymnasium[atari]) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./.venv/lib/python3.10/site-packages (from gymnasium[atari]) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./.venv/lib/python3.10/site-packages (from gymnasium[atari]) (0.0.4)\n",
      "Requirement already satisfied: ale_py>=0.9 in ./.venv/lib/python3.10/site-packages (from gymnasium[atari]) (0.11.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imageio in ./.venv/lib/python3.10/site-packages (2.37.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from imageio) (2.2.6)\n",
      "Requirement already satisfied: pillow>=8.3.2 in ./.venv/lib/python3.10/site-packages (from imageio) (12.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imageio-ffmpeg in ./.venv/lib/python3.10/site-packages (0.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.10/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in ./.venv/lib/python3.10/site-packages (from opencv-python) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.10/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ale_py\n",
    "%pip install gymnasium[atari]\n",
    "%pip install matplotlib\n",
    "%pip install imageio\n",
    "%pip install imageio-ffmpeg\n",
    "%pip install opencv-python\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d95e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ale_py\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import os\n",
    "import imageio\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "gym.register_envs(ale_py)\n",
    "env = gym.make('ALE/SpaceInvaders-v5', render_mode='rgb_array', frameskip=3, repeat_action_probability=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50931b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVATION SPACE\n",
      "Shape: (210, 160, 3)\n",
      "Data type: uint8\n",
      "Min value: 0, Max value: 181\n",
      "Total pixels: 100,800\n",
      "\n",
      "ACTION SPACE\n",
      "Type: Discrete(6)\n",
      "Number of actions: 6\n"
     ]
    }
   ],
   "source": [
    "# Environment analysis\n",
    "obs, info = env.reset()\n",
    "\n",
    "print(f\"OBSERVATION SPACE\")\n",
    "print(f\"Shape: {obs.shape}\")\n",
    "print(f\"Data type: {obs.dtype}\")\n",
    "print(f\"Min value: {obs.min()}, Max value: {obs.max()}\")\n",
    "print(f\"Total pixels: {np.prod(obs.shape):,}\")\n",
    "\n",
    "print(f\"\\nACTION SPACE\")\n",
    "print(f\"Type: {env.action_space}\")\n",
    "print(f\"Number of actions: {env.action_space.n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1688858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 0: NOOP\n",
      "Action 1: FIRE\n",
      "Action 2: RIGHT\n",
      "Action 3: LEFT\n",
      "Action 4: RIGHTFIRE\n",
      "Action 5: LEFTFIRE\n"
     ]
    }
   ],
   "source": [
    "# See what each action does\n",
    "action_meanings = env.unwrapped.get_action_meanings()\n",
    "for i, action in enumerate(action_meanings):\n",
    "    print(f\"Action {i}: {action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a54649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visulaise initial state\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.imshow(obs)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25eec913",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a8fd5a",
   "metadata": {},
   "source": [
    "## 3. Implementation\n",
    "\n",
    "### 3.1 Data Preprocessing\n",
    "\n",
    "Raw Atari frames are 210×160×3 RGB images, which is computationally expensive and contains unnecessary information such as the RGB aspect and thick borders. Our preprocessing pipeline applies the following transformations:\n",
    "\n",
    "1. **Frame skip (k=3):** Unlike most Atari games which use k=4, Space Invaders requires k=3 because the laser projectiles blink at a frequency that makes them invisible with k=4\n",
    "2. **Cropping:** Remove score display and ground (rows 20-195), reducing visual noise\n",
    "3. **Grayscale conversion:** Reduce from 3 channels to 1 as colour does not help in any way with gameplay\n",
    "4. **Resize:** Downsample to 84×84 for computational efficiency\n",
    "5. **Normalisation:** Scale pixel values from [0, 255] to [0, 1]\n",
    "6. **Frame stacking:** Stack 4 consecutive frames to capture motion and velocity information\n",
    "\n",
    "This reduces the input from 100,800 values per frame to 7,056 values per frame, while the 4-frame stack provides temporal context that allows the network to perceive movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "316d4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceInvadersPreprocessor(gym.Wrapper):\n",
    "    def __init__(self, env, frame_stack=4, im_size=84):\n",
    "        super().__init__(env)\n",
    "\n",
    "        # Initialise parameters\n",
    "        self.frame_stack = frame_stack\n",
    "        self.im_size = im_size\n",
    "        self.frames = deque(maxlen=frame_stack) # Initialise a deque (double ended queue) to hold stacked frames\n",
    "        \n",
    "        # Set the observation space\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0.0,\n",
    "            high=1.0,\n",
    "            shape=(frame_stack, im_size, im_size),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    def preprocess_frame(self, frame):\n",
    "        # Crop frame (remove the top and bottom part of the screen that don't contain relevant information like score and ground)\n",
    "        cropped = frame[20:195, :]\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(cropped, cv2.COLOR_RGB2GRAY)\n",
    "        # Resize frame to match the input size expected by the model\n",
    "        resized = cv2.resize(gray, (self.im_size, self.im_size), \n",
    "                            interpolation=cv2.INTER_AREA)\n",
    "        # Normalise the frame to a range [0, 1] for better training performance\n",
    "        normalised = resized.astype(np.float32) / 255.0 # Normalize pixel values to [0, 1]\n",
    "        \n",
    "        return normalised\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        obs, info = self.env.reset(**kwargs) # Reset the environment to start a new episode\n",
    "        processed = self.preprocess_frame(obs) # Preprocess the first frame\n",
    "        \n",
    "        # Initialise the frame stack with the preprocessed frame\n",
    "        for _ in range(self.frame_stack):\n",
    "            self.frames.append(processed)\n",
    "        \n",
    "        # Return the stacked frames (as a NumPy array) and the additional info\n",
    "        return np.array(self.frames, dtype=np.float32), info\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Take a step in the environment\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        # Preprocess the new frame from the environment\n",
    "        processed = self.preprocess_frame(obs)\n",
    "        # Add the new frame to the frame stack\n",
    "        self.frames.append(processed)\n",
    "        \n",
    "        # Return the stacked frames as the new state, along with the reward, etc\n",
    "        return np.array(self.frames, dtype=np.float32), reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "# Quick test\n",
    "# env = gym.make('ALE/SpaceInvaders-v5', render_mode='rgb_array', frameskip=3, repeat_action_probability=0.0)\n",
    "# env = SpaceInvadersPreprocessor(env)\n",
    "# state, _ = env.reset()\n",
    "# print(f\"State shape: {state.shape}, range: [{state.min():.2f}, {state.max():.2f}]\")\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf5bed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (210, 160, 3), dtype=uint8, range=[0, 181]\n",
      "Preprocessed: (4, 84, 84), dtype=float32, range=[0.00, 0.52]\n"
     ]
    }
   ],
   "source": [
    "# Create environments\n",
    "env_orig = gym.make('ALE/SpaceInvaders-v5', render_mode='rgb_array', frameskip=3, repeat_action_probability=0.0)\n",
    "env_wrap = SpaceInvadersPreprocessor(gym.make('ALE/SpaceInvaders-v5', render_mode='rgb_array', frameskip=3, repeat_action_probability=0.0))\n",
    "\n",
    "# Get initial frames from both environments\n",
    "orig_frame, _ = env_orig.reset(seed=42) # Reset the original environment and get the first raw frame\n",
    "preprocessed, _ = env_wrap.reset(seed=42) # Reset the wrapped environment (with preprocessing) and get the preprocessed frame stack\n",
    "\n",
    "# Take a few steps to see actual gameplay in both environments\n",
    "for _ in range(15):\n",
    "    orig_frame, _, _, _, _ = env_orig.step(1)  # FIRE action\n",
    "    preprocessed, _, _, _, _ = env_wrap.step(1)\n",
    "\n",
    "# Plot the comparison between the raw and preprocessed frames\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax1.imshow(orig_frame)\n",
    "ax1.set_title(f'Original: {orig_frame.shape}')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(preprocessed[0], cmap='gray')  # Show first frame from stack\n",
    "ax2.set_title(f'Preprocessed: {preprocessed.shape}')\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original: {orig_frame.shape}, dtype={orig_frame.dtype}, range=[{orig_frame.min()}, {orig_frame.max()}]\")\n",
    "print(f\"Preprocessed: {preprocessed.shape}, dtype={preprocessed.dtype}, range=[{preprocessed.min():.2f}, {preprocessed.max():.2f}]\")\n",
    "\n",
    "# Close environments\n",
    "env_orig.close()\n",
    "env_wrap.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b65ba8",
   "metadata": {},
   "source": [
    "### 3.2 Network Architecture\n",
    "\n",
    "The DQN follows the architecture from Mnih et al. (2015):\n",
    "\n",
    "**Convolutional Layers:**\n",
    "- Conv1: 32 filters, 8×8 kernel, stride 4 → extracts low-level features (edges, shapes)\n",
    "- Conv2: 64 filters, 4×4 kernel, stride 2 → mid-level features (alien patterns, shields)\n",
    "- Conv3: 64 filters, 3×3 kernel, stride 1 → high-level features (spatial relationships)\n",
    "\n",
    "**Fully Connected Layers:**\n",
    "- FC1: 3136 → 512 neurons with ReLU activation\n",
    "- FC2: 512 → 6 neurons (Q-values for each action)\n",
    "\n",
    "The convolutional layers extract spatial features from the stacked frames, while the fully connected layers map these features to action values. ReLU activations introduce non-linearity, allowing the network to learn complex policies.\n",
    "\n",
    "**Hyperparameter Summary:**\n",
    "\n",
    "| Parameter | Value | Notes |\n",
    "|-----------|-------|-------|\n",
    "| Replay buffer size | 200,000 | Stores recent transitions |\n",
    "| Batch size | 64 | Samples per training step |\n",
    "| Discount factor (γ) | 0.99 | High value for long-term planning |\n",
    "| Learning rate | 1e-4 | Adam optimizer |\n",
    "| Initial epsilon | 1.0 | Start with full exploration |\n",
    "| Final epsilon | 0.01 | End with 1% exploration |\n",
    "| Epsilon decay | 0.9995 | Multiplicative decay per step |\n",
    "| Target network update | 1000 steps | Hard update frequency |\n",
    "| Frame skip | 3 | Space Invaders specific |\n",
    "| Frame stack | 4 | Temporal context |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7b45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_actions=6):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        # Conv layers\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4) # Input of 4 channels and output of 32 feature maps\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2) # Input of 32 feature maps and outputting 64\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1) # Input of 64 feature mpas and outputting 64\n",
    "        \n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512) # FC layer with 512 neurons\n",
    "        self.fc2 = nn.Linear(512, n_actions)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # ReLU after - ConV1\n",
    "        x = F.relu(self.conv2(x)) # ReLU after - ConV2\n",
    "        x = F.relu(self.conv3(x)) # ReLU after - ConV3\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x)) # Apply final ReLU activation function to fully connected layer 1\n",
    "        return self.fc2(x) # Returns raw q-values for each action\n",
    "\n",
    "\n",
    "# Test it\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = DQN(n_actions=6).to(device)\n",
    "\n",
    "# # Test with dummy input (batch of 1, 4 frames, 84x84)\n",
    "# test_input = torch.randn(1, 4, 84, 84).to(device)\n",
    "# output = model(test_input)\n",
    "# print(f\"Input: {test_input.shape}, Output: {output.shape}\")\n",
    "# print(f\"Running on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3712559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=200000):\n",
    "        self.buffer = deque(maxlen=capacity) # Buffer is a deque which is a double ended queue which will remove oldest element automaticlly when it reaches capacity\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done)) # Appends new experience (state, action, reward, next_state, done) to buffer\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size) # Randomly sample 'batch_size' number of experiences from the buffer\n",
    "        states, actions, rewards, next_states, dones = zip(*batch) # unzip batch into individual components\n",
    "        \n",
    "        return (\n",
    "            torch.FloatTensor(np.array(states)),\n",
    "            torch.LongTensor(actions),\n",
    "            torch.FloatTensor(rewards),\n",
    "            torch.FloatTensor(np.array(next_states)),\n",
    "            torch.FloatTensor(dones)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer) # Returns length/size of buffer\n",
    "\n",
    "\n",
    "# Test\n",
    "# buffer = ReplayBuffer(capacity=1000)\n",
    "# buffer.push(np.random.rand(4, 84, 84), 2, 10, np.random.rand(4, 84, 84), False)\n",
    "# print(f\"Buffer size: {len(buffer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9bb51c",
   "metadata": {},
   "source": [
    "### 3.3 Q-Learning Update Mechanism\n",
    "\n",
    "The Q-learning update happens in train_step() and is the main component of how our agent learns. The basic idea comes from the Bellman equation, which says that the value of taking an action in a state equals the immediate reward plus the discounted value of whatever state you end up in:\n",
    "\n",
    "```\n",
    "Q*(s, a) = r + γ * max_a' Q*(s', a')\n",
    "```\n",
    "\n",
    "Here r is the reward you get right away, γ is the discount factor (we use 0.99), and s' is the next state.\n",
    "\n",
    "**How train_step() works:**\n",
    "\n",
    "First, we sample 32 random transitions from the replay buffer. Each transition contains (state, action, reward, next_state, done). Sampling randomly breaks the correlation between consecutive experiences - otherwise the network would see similar states back-to-back and might not learn general patterns.\n",
    "\n",
    "Next, we get the current Q-values by passing states through the online network. The network outputs Q-values for all 6 actions, but we only care about the Q-value for the action we actually took, so we use `.gather(1, actions)` to pull out just those values.\n",
    "\n",
    "Then we compute the target Q-values - what the Q-values *should* be according to the Bellman equation. For Standard DQN, we use the target network to find the maximum Q-value at the next state. For Double DQN, we do something smarter: the online network picks which action looks best, then the target network evaluates that action. This reduces the overestimation problem that standard DQN has.\n",
    "\n",
    "The target becomes `rewards + gamma * next_q * (1 - dones)`. The `(1 - dones)` part zeros out the future reward if the episode ended - there's no future reward when you're in a terminal state.\n",
    "\n",
    "For the loss function, we use Huber loss (`F.smooth_l1_loss`) instead of regular MSE. Huber loss behaves like MSE for small errors but like MAE for large errors, which prevents the occasional weird experience from causing huge gradient updates.\n",
    "\n",
    "Finally, we do standard backpropagation with gradient clipping (max norm of 10). Every 1000 training steps, we copy the online network's weights to the target network.\n",
    "\n",
    "**Why use two separate networks?**\n",
    "\n",
    "If we used the same network to both generate predictions and compute targets, we'd be chasing a moving target. The target network stays fixed for 1000 steps, giving us stable targets to learn against. This prevents the oscillations and instability that happen when your targets keep changing as you learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa208ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, n_actions=6, double_dqn=False):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.n_actions = n_actions\n",
    "        self.double_dqn = double_dqn  # Toggle for Double DQN\n",
    "        \n",
    "        # Networks\n",
    "        self.online_net = DQN(n_actions).to(self.device) # Online network (main network)\n",
    "        self.target_net = DQN(n_actions).to(self.device) # Target network (for stable targets)\n",
    "        self.target_net.load_state_dict(self.online_net.state_dict()) # Copy online net. weights to target net.\n",
    "        \n",
    "        # Training\n",
    "        self.optimizer = optim.Adam(self.online_net.parameters(), lr=1e-4)\n",
    "        self.replay_buffer = ReplayBuffer(capacity=200000) # replay buffer for experience replay\n",
    "        \n",
    "        # Hyperparameters for Q-Learning\n",
    "        self.gamma = 0.99 # Discount factor (γ)\n",
    "        self.epsilon = 1.0 # Epsilon for epsilon-greedy policy\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay_frames = 2_000_000 # Epsilon decay frames\n",
    "        self.batch_size = 64\n",
    "        self.target_update_freq = 1000 # Frequency of target network updates\n",
    "        self.steps = 0 # Step counter for epsilon decay and target network updates\n",
    "    \n",
    "    def choose_action(self, state, training=True):\n",
    "        # Epsilon-greedy action selection\n",
    "        if training and random.random() < self.epsilon:\n",
    "            return random.randrange(self.n_actions) # Random action (exploration)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "            q_values = self.online_net(state_tensor) # Get Q-values for all actions\n",
    "            return q_values.argmax().item() # Return the action with highest Q-value (exploitation)\n",
    "\n",
    "    \n",
    "    def train_step(self):\n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return None\n",
    "        \n",
    "        # Sample a batch of experiences from the replay buffer\n",
    "        states, actions, rewards, next_states, dones = self.replay_buffer.sample(self.batch_size)\n",
    "        states = states.to(self.device)\n",
    "        actions = actions.to(self.device)\n",
    "        rewards = rewards.to(self.device)\n",
    "        next_states = next_states.to(self.device)\n",
    "        dones = dones.to(self.device)\n",
    "        \n",
    "        # Get current Q-values (online network)\n",
    "        current_q = self.online_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        # Calculate target Q-values\n",
    "        with torch.no_grad():\n",
    "            if self.double_dqn:\n",
    "                # Double DQN: online network selects, target network evaluates\n",
    "                next_actions = self.online_net(next_states).argmax(1, keepdim=True)  # Online network's action choice\n",
    "                next_q = self.target_net(next_states).gather(1, next_actions).squeeze(1) # Target network's Q-value for chosen action\n",
    "            else:\n",
    "                # Standard DQN: target network does both\n",
    "                next_q = self.target_net(next_states).max(1)[0]\n",
    "\n",
    "             # Bellman target: rewards + gamma * next_q * (1 - dones)\n",
    "            target_q = rewards + self.gamma * next_q * (1 - dones)\n",
    "        \n",
    "        # Compute loss and update\n",
    "        loss = F.smooth_l1_loss(current_q, target_q) # Huber loss instead of MSE\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.online_net.parameters(), max_norm=10) # Gradient clipping\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Update target network weights every 1000 steps\n",
    "        self.steps += 1\n",
    "        if self.steps % self.target_update_freq == 0:\n",
    "            self.target_net.load_state_dict(self.online_net.state_dict())\n",
    "\n",
    "        return loss.item() # Return the loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "854f03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(episodes=1000, log_interval=10, double_dqn=False, save_dir='outputs'):\n",
    "    import os\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Create the environment and preprocess it\n",
    "    env = gym.make('ALE/SpaceInvaders-v5', render_mode='rgb_array', frameskip=3, repeat_action_probability=0.0)\n",
    "    env = SpaceInvadersPreprocessor(env)\n",
    "\n",
    "    # Initialise the DQNAgent\n",
    "    agent = DQNAgent(n_actions=6, double_dqn=double_dqn)\n",
    "    \n",
    "    # Mode decision? Standard or Double \n",
    "    mode = 'double_dqn' if double_dqn else 'standard_dqn'\n",
    "    print(f\"Training {mode.replace('_', ' ').title()} on {agent.device}\")\n",
    "    \n",
    "    # History to track performance over time\n",
    "    history = {\n",
    "        'episode_rewards': [],\n",
    "        'losses': [],\n",
    "        'epsilons': [],\n",
    "        'avg_q_values': [],\n",
    "        'episode_lengths': [],\n",
    "        'total_frames': []\n",
    "    }\n",
    "    \n",
    "     # Training loop for 'episodes'\n",
    "    for episode in range(episodes):\n",
    "        # Epsilon decay based on frames\n",
    "        if agent.steps < agent.epsilon_decay_frames:\n",
    "            agent.epsilon = 1.0 - 0.99 * (agent.steps / agent.epsilon_decay_frames)  # Gradually decay epsilon\n",
    "        else:\n",
    "            agent.epsilon = agent.epsilon_min # Use the minimum epsilon value\n",
    "        \n",
    "        state, _ = env.reset() # Reset the environment for each episode\n",
    "        episode_reward = 0  # Initialise episode reward\n",
    "        episode_loss = [] # Track losses per episode\n",
    "        episode_q_values = [] # Track Q-values for monitoring\n",
    "        steps = 0  # Track number of steps per episode\n",
    "        done = False # Track if episode is done\n",
    "        \n",
    "        while not done:\n",
    "            action = agent.choose_action(state) # Epsilon-greedy action selection (exploration vs. exploitation)\n",
    "            \n",
    "            # Take the action and get the next state and reward\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated # Episode ends when either terminated or truncated\n",
    "            \n",
    "            # Store the experience in the replay buffer\n",
    "            agent.replay_buffer.push(state, action, reward, next_state, float(done))\n",
    "            \n",
    "            # Perform a training step (Q-value update)\n",
    "            loss = agent.train_step()\n",
    "            if loss is not None:\n",
    "                episode_loss.append(loss) # Append loss if there was an update\n",
    "                \n",
    "                # Track Q-values periodically (every 100 steps)\n",
    "                if steps % 100 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        state_t = torch.FloatTensor(state).unsqueeze(0).to(agent.device)\n",
    "                        q_vals = agent.online_net(state_t) # Get Q-values from the online network\n",
    "                        episode_q_values.append(q_vals.max().item()) # Append the max Q-value\n",
    "            \n",
    "            state = next_state # Move to the next state\n",
    "            episode_reward += reward # Update total reward for this episode\n",
    "            steps += 1\n",
    "        \n",
    "        # Record episode statistics\n",
    "        history['episode_rewards'].append(episode_reward)\n",
    "        history['losses'].append(np.mean(episode_loss) if episode_loss else 0) # Average loss for the episode\n",
    "        history['epsilons'].append(agent.epsilon) # Current epsilon value\n",
    "        history['avg_q_values'].append(np.mean(episode_q_values) if episode_q_values else 0) # Average Q-value\n",
    "        history['episode_lengths'].append(steps) # Number of steps in this episode\n",
    "        history['total_frames'].append(agent.steps) # Total number of frames processed\n",
    "        \n",
    "        # Log progress every 'log_interval' episodes\n",
    "        if episode % log_interval == 0:\n",
    "            avg_reward = np.mean(history['episode_rewards'][-100:]) # Average reward of the last 100 eps\n",
    "            avg_loss = np.mean(history['losses'][-100:]) if history['losses'] else 0 # Average reward of the last 100 eps\n",
    "            print(f\"Episode {episode:4d} | Reward: {episode_reward:6.0f} | \"\n",
    "                  f\"Avg100: {avg_reward:7.1f} | Loss: {avg_loss:.4f} | \"\n",
    "                  f\"Epsilon: {agent.epsilon:.3f}\")\n",
    "        \n",
    "        # Save checkpoints every 100 episodes\n",
    "        if episode > 0 and episode % 100 == 0:\n",
    "            checkpoint_path = f'{save_dir}/dqn_{mode}_ep{episode}.pth'\n",
    "            torch.save({\n",
    "                'episode': episode,\n",
    "                'model_state_dict': agent.online_net.state_dict(),\n",
    "                'optimizer_state_dict': agent.optimizer.state_dict(),\n",
    "                'epsilon': agent.epsilon,\n",
    "                'history': history\n",
    "            }, checkpoint_path) # Save model, optimizer, epsilon, and training history\n",
    "            print(f\"  Saved checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Save the final model after training\n",
    "    final_path = f'{save_dir}/dqn_{mode}_final.pth'\n",
    "    torch.save({\n",
    "        'model_state_dict': agent.online_net.state_dict(),\n",
    "        'history': history\n",
    "    }, final_path) # Save final trained model and history\n",
    "    \n",
    "    env.close() # Close the environment\n",
    "    return agent, history # Return the trained agent and its history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30667fd",
   "metadata": {},
   "source": [
    " ## 4. Training Plots\n",
    " \n",
    " The following visualizations track the agent's learning progress:\n",
    " - **Episode Rewards:** Raw and smoothed rewards over training\n",
    " - **Loss Curve:** TD error magnitude over time\n",
    " - **Epsilon Decay:** Exploration rate schedule\n",
    " - **Q-Value Estimates:** Average predicted Q-values (indicator of value learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "468761e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history, title_prefix='DQN', save_path=None):    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Episode Rewards with multiple moving averages\n",
    "    ax1 = axes[0, 0]\n",
    "    rewards = history['episode_rewards']\n",
    "    ax1.plot(rewards, alpha=0.3, color='blue', label='Raw')\n",
    "    \n",
    "    for window, color in [(50, 'orange'), (100, 'red')]:\n",
    "        if len(rewards) >= window:\n",
    "            ma = np.convolve(rewards, np.ones(window)/window, mode='valid')\n",
    "            ax1.plot(range(window-1, len(rewards)), ma, \n",
    "                    label=f'{window}-Episode MA', color=color, linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Episode')\n",
    "    ax1.set_ylabel('Total Reward')\n",
    "    ax1.set_title(f'{title_prefix}: Episode Rewards')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Training Loss\n",
    "    ax2 = axes[0, 1]\n",
    "    losses = history['losses']\n",
    "    ax2.plot(losses, alpha=0.3, color='blue', label='Raw')\n",
    "    \n",
    "    if len(losses) >= 50:\n",
    "        loss_ma = np.convolve(losses, np.ones(50)/50, mode='valid')\n",
    "        ax2.plot(range(49, len(losses)), loss_ma, \n",
    "                color='red', linewidth=2, label='50-Episode MA')\n",
    "    \n",
    "    ax2.set_xlabel('Episode')\n",
    "    ax2.set_ylabel('Average Loss')\n",
    "    ax2.set_title(f'{title_prefix}: Training Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Epsilon Decay\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(history['epsilons'], color='green', linewidth=2)\n",
    "    ax3.set_xlabel('Episode')\n",
    "    ax3.set_ylabel('Epsilon')\n",
    "    ax3.set_title(f'{title_prefix}: Exploration Rate (Epsilon)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim(0, 1.05)\n",
    "    \n",
    "    # Plot 4: Average Q-Values\n",
    "    ax4 = axes[1, 1]\n",
    "    q_values = history['avg_q_values']\n",
    "    ax4.plot(q_values, alpha=0.3, color='purple', label='Raw')\n",
    "    \n",
    "    if len(q_values) >= 50:\n",
    "        q_ma = np.convolve(q_values, np.ones(50)/50, mode='valid')\n",
    "        ax4.plot(range(49, len(q_values)), q_ma, \n",
    "                color='darkviolet', linewidth=2, label='50-Episode MA')\n",
    "    \n",
    "    ax4.set_xlabel('Episode')\n",
    "    ax4.set_ylabel('Average Q-Value')\n",
    "    ax4.set_title(f'{title_prefix}: Q-Value Estimates')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Saved plot: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48f48e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reward variance over training\n",
    "def plot_variance(history, window=50, save_path=None):\n",
    "    # Plot variance of rewards over training.\n",
    "    rewards = history['episode_rewards']\n",
    "    \n",
    "    variances = []\n",
    "    for i in range(window, len(rewards)):\n",
    "        variances.append(np.var(rewards[i-window:i]))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(window, len(rewards)), variances, color='green', alpha=0.7)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Variance')\n",
    "    plt.title(f'Reward Variance (window={window})')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "144e5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(history_standard, history_double, save_path=None):\n",
    "    # Compare Standard DQN vs Double DQN performance.\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Reward comparison\n",
    "    ax1 = axes[0]\n",
    "    for history, label, color in [(history_standard, 'Standard DQN', 'blue'),\n",
    "                                   (history_double, 'Double DQN', 'red')]:\n",
    "        rewards = history['episode_rewards']\n",
    "        if len(rewards) >= 100:\n",
    "            ma = np.convolve(rewards, np.ones(100)/100, mode='valid')\n",
    "            ax1.plot(range(99, len(rewards)), ma, label=label, color=color, linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Episode')\n",
    "    ax1.set_ylabel('Average Reward (100-ep)')\n",
    "    ax1.set_title('Reward Comparison: Standard vs Double DQN')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Q-value comparison\n",
    "    ax2 = axes[1]\n",
    "    for history, label, color in [(history_standard, 'Standard DQN', 'blue'),\n",
    "                                   (history_double, 'Double DQN', 'red')]:\n",
    "        q_vals = history['avg_q_values']\n",
    "        if len(q_vals) >= 50:\n",
    "            ma = np.convolve(q_vals, np.ones(50)/50, mode='valid')\n",
    "            ax2.plot(range(49, len(q_vals)), ma, label=label, color=color, linewidth=2)\n",
    "    \n",
    "    ax2.set_xlabel('Episode')\n",
    "    ax2.set_ylabel('Average Q-Value')\n",
    "    ax2.set_title('Q-Value Estimates: Standard vs Double DQN')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c07f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards_vs_frames(history, title_prefix='DQN', save_path=None):\n",
    "    # Plot rewards over total frames (not episodes).\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Get cumulative frame count at each episode end\n",
    "    frames = history['total_frames']\n",
    "    rewards = history['episode_rewards']\n",
    "    \n",
    "    # Plot raw\n",
    "    ax.scatter(frames, rewards, alpha=0.3, s=10, color='blue', label='Raw')\n",
    "    \n",
    "    # Moving average\n",
    "    if len(rewards) >= 100:\n",
    "        ma = np.convolve(rewards, np.ones(100)/100, mode='valid')\n",
    "        ax.plot(frames[99:], ma, color='red', linewidth=2, label='100-Episode MA')\n",
    "    \n",
    "    ax.set_xlabel('Frames')\n",
    "    ax.set_ylabel('Episode Reward')\n",
    "    ax.set_title(f'{title_prefix}: Rewards vs Frames')\n",
    "    ax.axvline(x=1e6, color='gray', linestyle='--', alpha=0.5, label='1M frames')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfafa49",
   "metadata": {},
   "source": [
    " ## 5. Video Recording\n",
    " \n",
    " We record gameplay videos to visually demonstrate learning progress:\n",
    " - Pre-training (random policy)\n",
    " - Post-training (learned policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36c42972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_video(agent, filename, episodes=1, max_steps=2000, fps=30):\n",
    "    # Record gameplay video of the agent.\n",
    "    \n",
    "    env = gym.make('ALE/SpaceInvaders-v5', render_mode='rgb_array', frameskip=3, repeat_action_probability=0.0)\n",
    "    env = SpaceInvadersPreprocessor(env)\n",
    "    \n",
    "    frames = []\n",
    "    total_reward = 0\n",
    "    \n",
    "    for ep in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        \n",
    "        while not done and steps < max_steps:\n",
    "            # Get raw frame for video\n",
    "            raw_frame = env.env.render()\n",
    "            frames.append(raw_frame)\n",
    "            \n",
    "            # Agent selects action (no exploration for evaluation)\n",
    "            action = agent.choose_action(state, training=False)\n",
    "            state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    import imageio\n",
    "    imageio.mimsave(filename, frames, fps=fps)\n",
    "    print(f\"Saved video: {filename} ({len(frames)} frames, reward: {total_reward})\")\n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f6bf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_random_agent(filename, episodes=1, max_steps=2000, fps=30):\n",
    "    # Record a random agent for baseline comparison.\n",
    "    \n",
    "    env = gym.make('ALE/SpaceInvaders-v5', render_mode='rgb_array', frameskip=3, repeat_action_probability=0.0)\n",
    "    \n",
    "    frames = []\n",
    "    total_reward = 0\n",
    "    \n",
    "    for ep in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        \n",
    "        while not done and steps < max_steps:\n",
    "            frames.append(env.render())\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    import imageio\n",
    "    imageio.mimsave(filename, frames, fps=fps)\n",
    "    print(f\"Saved random agent video: {filename} (reward: {total_reward})\")\n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69acea0",
   "metadata": {},
   "source": [
    "## 6. Evaluation of Results\n",
    "\n",
    "RL agents need different evaluation metrics compared to the supervised learning we're used to. You can't just calculate accuracy or F1 score because there's no \"correct answer\" for what action to take in each state.\n",
    "\n",
    "**Main metrics we track:**\n",
    "\n",
    "- **Average Episode Reward:** How many points does the agent score on average.\n",
    "- **Maximum Score:** The best run the agent has managed'\n",
    "- **Convergence Speed:** How many episodes before performance levels off? Faster convergence means more efficient learning.\n",
    "- **Stability:** How much the scores bounce around. Lower variance means the agent plays more consistently.\n",
    "\n",
    "**Why the usual ML metrics don't work here:**\n",
    "\n",
    "The metrics we learned for supervised learning (accuracy, precision, recall, F1) only make sense when you have labeled data with clear right/wrong answers. RL is totally different because the agent is trying to figure out a strategy to maximize long-term reward no classify single actions.\n",
    "\n",
    "- There's no dataset of \"correct\" actions for each game state - the agent has to discover good strategies on its own\n",
    "- Success is about the total reward over an entire episode, not getting individual decisions right\n",
    "- Overfitting in RL looks different - it's called \"primacy bias\" where the agent gets too attached to strategies it learned early on. That's why we use experience replay, to mix old and new experiences together\n",
    "- Underfitting happens when the network is too small or we throw away important visual info during preprocessing, so the agent can't learn proper strategies\n",
    "\n",
    "**What we actually measure:**\n",
    "\n",
    "The main metric is just average episode reward, tracked with a 100-episode window. We also look at how stable those rewards are (high variance means inconsistent play), and how quickly the agent improves.\n",
    "\n",
    "For Space Invaders specifically, we can compare against known benchmarks:\n",
    "- Random play: ~150 points\n",
    "- Average human: ~1,652 points  \n",
    "- Original DQN paper: ~1,976 points (beat human by 21%)\n",
    "- Our goal: 800-1500 for Standard DQN, 1000-2000 for Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41dcc870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(agent, n_episodes=30, verbose=True):\n",
    "    # Evaluate trained agent over multiple episodes\n",
    "    \n",
    "    # Create the environment and preprocess it the same as training environment\n",
    "    env = gym.make('ALE/SpaceInvaders-v5', render_mode='rgb_array', frameskip=3, repeat_action_probability=0.0)\n",
    "    env = SpaceInvadersPreprocessor(env) # Preprcoess pipeline\n",
    "    \n",
    "    rewards = [] \n",
    "    episode_lengths = []\n",
    "    \n",
    "    # Loop over the specified number of episodes\n",
    "    for ep in range(n_episodes):\n",
    "        state, _ = env.reset() # Reset the environment at the start of each episode\n",
    "        episode_reward = 0 # Initialise the reward for the current episode\n",
    "        steps = 0 # Initialise the number of steps taken in the current episode\n",
    "        done = False # # Flag to track if the episode is done\n",
    "        \n",
    "        # Run the episode\n",
    "        while not done:\n",
    "            # Choose an action from the policy using the trained agent\n",
    "            action = agent.choose_action(state, training=False) # No exploration (set training=False)\n",
    "            state, reward, terminated, truncated, _ = env.step(action) # Take the action and get the next state and reward\n",
    "            reward = np.clip(reward, -1, 1) # Clip the reward to be between -1 and 1 \n",
    "            done = terminated or truncated # Check if the episode is done (terminated or truncated)\n",
    "            episode_reward += reward # Update the cumulative reward for this episode\n",
    "            steps += 1\n",
    "        \n",
    "        # Record the results for the current episode\n",
    "        rewards.append(episode_reward)\n",
    "        episode_lengths.append(steps)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Episode {ep+1}/{n_episodes}: Reward = {episode_reward}\")\n",
    "    \n",
    "    env.close() # Close the environment after evaluation is done\n",
    "    \n",
    "    # Compute statistics about the evaluation results\n",
    "    stats = {\n",
    "        'mean_reward': np.mean(rewards), # Average reward across all episodes\n",
    "        'std_reward': np.std(rewards), # Standard deviation of rewards across episodes\n",
    "        'max_reward': np.max(rewards),\n",
    "        'min_reward': np.min(rewards),\n",
    "        'mean_length': np.mean(episode_lengths), # Average number of steps per episode\n",
    "        'all_rewards': rewards # List of rewards for all episodes\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nEvaluation Results ({n_episodes} episodes):\")\n",
    "    print(f\"  Mean Reward:  {stats['mean_reward']:.1f} ± {stats['std_reward']:.1f}\")\n",
    "    print(f\"  Max Reward:   {stats['max_reward']:.0f}\")\n",
    "    print(f\"  Min Reward:   {stats['min_reward']:.0f}\")\n",
    "    print(f\"  Mean Length:  {stats['mean_length']:.0f} steps\")\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent_research_md",
   "metadata": {},
   "source": [
    "## 7. Independent Research: Double DQN and Maximization Bias\n",
    "\n",
    "### The Problem: Maximization Bias in Standard DQN\n",
    "\n",
    "Standard DQN has a pretty important flaw when it comes to how it computes its Q-values. Basically, when the agent is figuring out what action to take, it uses the same network to both pick the best action and evaluate how good that action is. The target Q-value looks like this:\n",
    "\n",
    "```\n",
    "target = r + γ * max_a Q_target(s', a)\n",
    "```\n",
    "\n",
    "But the problem with this is that the Q-values are just estimates. They aren’t perfect, so they have some noise in them. When you take the maximum Q-value over a bunch of noisy estimates, you’re more likely to pick the one that's overestimated, just by chance. Once you do that, you reinforce this overestimated value in future updates, and the problem just keeps getting worse. So, over time, the agent starts making decisions based on inflated Q-values that aren’t really accurate.\n",
    "\n",
    "### The Solution: Double DQN\n",
    "\n",
    "Double DQN (proposed by van Hasselt et al. in 2016) addresses this problem by splitting the task of action selection and evaluation between two networks:\n",
    "\n",
    "```\n",
    "# Standard DQN (overestimates):\n",
    "target = r + γ * Q_target(s', argmax_a Q_target(s', a))\n",
    "\n",
    "# Double DQN (more accurate):\n",
    "best_action = argmax_a Q_online(s', a)    # Online network picks the action\n",
    "target = r + γ * Q_target(s', best_action) # Target network evaluates the action\n",
    "```\n",
    "\n",
    "The key idea here is that we use two networks. The online network picks which action seems best, then the target network evaluates how good that action actually is. Because the two networks have different errors, they don’t overestimate the Q-values in the same direction, which leads to more stable learning.\n",
    "\n",
    "### How We Implemented It\n",
    "\n",
    "The Double DQN update happens in the `train_step()` function and is controlled by a flag (`self.double_dqn`). Here's how we implemented it:\n",
    "\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    if self.double_dqn:\n",
    "        # Double DQN: online network selects the action, target network evaluates it\n",
    "        next_actions = self.online_net(next_states).argmax(1, keepdim=True)\n",
    "        next_q = self.target_net(next_states).gather(1, next_actions).squeeze(1)\n",
    "    else:\n",
    "        # Standard DQN: target network does both selection and evaluation\n",
    "        next_q = self.target_net(next_states).max(1)[0]\n",
    "    \n",
    "    target_q = rewards + self.gamma * next_q * (1 - dones)\n",
    "```\n",
    "\n",
    "This part of the code is where we decide which network does the action selection (online network) and which network evaluates the chosen action (target network). If we’re using Double DQN, the online network picks the best action, and the target network evaluates how good that action actually is.\n",
    "\n",
    "### Why This Matters for Space Invaders\n",
    "\n",
    "In the case of Space Invaders, there are many situations where multiple actions are almost equally good. For example, the agent might be in a position where it's safe to move slightly left or right, and both options are almost equally good. However, if the agent is using Standard DQN, it might randomly overestimate the value of one of these positions, causing it to keep choosing that action even though it's not actually better. Double DQN helps by giving a more accurate estimate of Q-values, which leads to better performance and more stable learning.\n",
    "\n",
    "### Other Stuff That Helps DQN Performance\n",
    "\n",
    "* **Catastrophic Forgetting:**\n",
    "  This happens when the network suddenly forgets how to handle old situations while learning new ones. DQN tries to avoid this by using experience replay. Instead of just learning from the most recent experiences, the agent stores the last 100,000 transitions and samples randomly from this memory. This way, the agent doesn’t forget how to handle old situations.\n",
    "\n",
    "* **Random Seed Stuff:**\n",
    "  Setting random seeds makes the training process reproducible. So, if you set the same seed, you'll get the same results, which is super helpful for debugging and comparing things like Standard DQN vs Double DQN. But relying on just one seed can be misleading because you might have gotten lucky or unlucky. Ideally, you’d run the training with multiple seeds and average the results, but we didn’t have time to do that due to the training duration.\n",
    "\n",
    "* **Regularization:**\n",
    "  To prevent exploding gradients and keep things stable, we use gradient clipping (max norm = 10). We could try other techniques like L2 weight decay, dropout, or batch normalisation, but since the original DQN paper didn’t use these, we decided to keep things simple and stick with what was used in the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_header_md",
   "metadata": {},
   "source": [
    "## 8. Training and Results\n",
    "\n",
    "We train both Standard DQN and Double DQN agents to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_standard_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Standard Dqn on cuda\n",
      "Episode    0 | Reward:     80 | Avg100:    80.0 | Loss: 0.1084 | Epsilon: 1.000\n",
      "  Saved checkpoint: outputs/dqn_standard_dqn_ep100.pth\n",
      "Episode  200 | Reward:     90 | Avg100:   143.2 | Loss: 0.8339 | Epsilon: 0.930\n",
      "  Saved checkpoint: outputs/dqn_standard_dqn_ep200.pth\n",
      "  Saved checkpoint: outputs/dqn_standard_dqn_ep300.pth\n"
     ]
    }
   ],
   "source": [
    "# Train Standard DQN\n",
    "agent_standard, history_standard = train(\n",
    "    episodes=5000, \n",
    "    log_interval=200,\n",
    "    double_dqn=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_standard_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Standard DQN training curves\n",
    "plot_training_curves(history_standard, title_prefix='Standard DQN', save_path='outputs/standard_dqn_training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca57de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance(history_standard, save_path='outputs/variance_standard.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rewards_vs_frames(history_standard, title_prefix='Standard DQN', save_path='outputs/standard_dqn_frames.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_double_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Double DQN\n",
    "agent_double, history_double = train(\n",
    "    episodes=5000,  \n",
    "    log_interval=200,\n",
    "    double_dqn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_double_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Double DQN training curves\n",
    "plot_training_curves(history_double, title_prefix='Double DQN',save_path='outputs/double_dqn_training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance(history_double, save_path='outputs/variance_double.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d583c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rewards_vs_frames(history_double, title_prefix='Double DQN',\n",
    "                      save_path='outputs/double_dqn_frames.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Standard vs Double DQN\n",
    "plot_comparison(history_standard, history_double,\n",
    "               save_path='outputs/dqn_comparison.png')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Loop through each history (Standard DQN and Double DQN)\n",
    "for history, label, color in [(history_standard, 'Standard DQN', 'blue'),\n",
    "                               (history_double, 'Double DQN', 'red')]:\n",
    "    frames = history['total_frames']\n",
    "    rewards = history['episode_rewards']\n",
    "    if len(rewards) >= 100:\n",
    "        ma = np.convolve(rewards, np.ones(100)/100, mode='valid')\n",
    "        ax.plot(frames[99:], ma, label=label, color=color, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Total Frames')\n",
    "ax.set_ylabel('Average Reward (100-ep MA)')\n",
    "ax.set_title('Comparison: Rewards vs Frames')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.savefig('outputs/comparison_frames.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Standard DQN - Final 100-ep avg: {np.mean(history_standard['episode_rewards'][-100:]):.1f}\")\n",
    "print(f\"Double DQN   - Final 100-ep avg: {np.mean(history_double['episode_rewards'][-100:]):.1f}\")\n",
    "print(f\"Standard DQN - Max score: {max(history_standard['episode_rewards']):.0f}\")\n",
    "print(f\"Double DQN   - Max score: {max(history_double['episode_rewards']):.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_agents_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both agents\n",
    "print(\"\\nEvaluating Standard DQN:\")\n",
    "stats_standard = evaluate_agent(agent_standard, n_episodes=100)\n",
    "\n",
    "print(\"\\nEvaluating Double DQN:\")\n",
    "stats_double = evaluate_agent(agent_double, n_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "record_videos_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record videos for demonstration\n",
    "\n",
    "# Random agent \n",
    "print(\"Recording random agent\")\n",
    "record_random_agent('outputs/random_agent.mp4')\n",
    "\n",
    "# Trained agents\n",
    "print(\"\\nRecording Standard DQN agent\")\n",
    "record_video(agent_standard, 'outputs/standard_dqn_agent.mp4')\n",
    "\n",
    "print(\"\\nRecording Double DQN agent\")\n",
    "record_video(agent_double, 'outputs/double_dqn_agent.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results_analysis_md",
   "metadata": {},
   "source": [
    "### Analysis of Results\n",
    "\n",
    "**Expected Observations:**\n",
    "\n",
    "1. **Q-Value Estimates:** Double DQN should show lower Q-value estimates than Standard DQN because it reduces overestimation bias. Higher Q-values in Standard DQN don't mean better performance - they often indicate inflated estimates.\n",
    "\n",
    "2. **Training Stability:** Double DQN typically shows more stable training curves with lower variance in episode rewards.\n",
    "\n",
    "3. **Final Performance:** Double DQN often achieves higher final scores, particularly in games like Space Invaders where many actions have similar values.\n",
    "\n",
    "4. **Video Analysis:** The trained agents should show strategic behavior like:\n",
    "   - Positioning to avoid alien fire\n",
    "   - Targeting specific aliens (higher rows for more points)\n",
    "   - Using shields for cover\n",
    "   - Attempting to hit the mystery ship when it appears"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references_md",
   "metadata": {},
   "source": [
    "## 9. References\n",
    "\n",
    "1. Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Hassabis, D. (2015). Human-level control through deep reinforcement learning. *Nature*, 518(7540), 529-533.\n",
    "\n",
    "2. van Hasselt, H., Guez, A., & Silver, D. (2016). Deep reinforcement learning with double Q-learning. *Proceedings of the AAAI Conference on Artificial Intelligence*, 30(1).\n",
    "\n",
    "3. Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction* (2nd ed.). MIT Press.\n",
    "\n",
    "4. Gymnasium Documentation. https://gymnasium.farama.org/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
